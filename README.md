# VeriPaper - AI Research Authenticity Platform

A full-stack machine learning application for analyzing research papers to detect plagiarism, AI-generated content, citation validity issues, and statistical anomalies.

## ğŸ¯ Key Features

### Core Analysis Modules
- **ğŸ“š Plagiarism Detection**: Semantic similarity search using SBERT embeddings + FAISS vector database
- **ğŸ¤– AI Generation Detection**: Hybrid approach combining perplexity analysis + machine learning features
- **ğŸ”— Citation Validation**: DOI extraction and CrossRef API verification
- **ğŸ“Š Statistical Risk Assessment**: Anomaly detection in statistical claims and p-values

### User Interface
- ğŸ¨ **Modern Dashboard**: Real-time analysis with visual score gauges
- ğŸ“¥ **Multi-Format Export**: PDF reports, CSV tables, JSON data
- ğŸ“‹ **Analysis History**: Automatic tracking with browser localStorage
- ğŸŒ“ **Dark/Light Theme**: Customizable appearance
- ğŸ“± **Responsive Design**: Mobile-friendly interface

## ğŸš€ Quick Start

### One-Command Setup (Windows)
```bash
start-dev.bat
```

### Manual Setup

**Terminal 1 - Backend:**
```bash
cd backend
python -m venv venv
venv\Scripts\activate
pip install -r requirements.txt
python -m uvicorn app.main:app --reload --port 8000
```

**Terminal 2 - Frontend:**
```bash
cd frontend
npm install
npm run dev
```

Visit `http://localhost:5173` and start analyzing!

## ğŸ“– Documentation

- **[QUICKSTART.md](QUICKSTART.md)** - 5-minute setup guide (start here!)
- **[DEVELOPMENT.md](DEVELOPMENT.md)** - Detailed architecture and development guide
- **[backend/](backend/)** - Backend API documentation
- **[frontend/](frontend/)** - Frontend component guide

## ğŸ’» System Requirements

- Python 3.11+
- Node.js 16+
- Modern web browser
- 2GB RAM minimum
- 500MB disk space

## ğŸ“Š Analysis Results

Each analysis returns:

| Metric | Range | Interpretation |
|--------|-------|-----------------|
| **Plagiarism Score** | 0-100% | % similarity to known papers (lower = better) |
| **AI Probability** | 0-100% | % likelihood content is AI-written (lower = better) |
| **Citation Validity** | 0-100% | % of valid citations (higher = better) |
| **Statistical Risk** | 0-100% | Risk level in statistical claims (lower = better) |
| **Overall Credibility** | 0-100% | Combined authenticity score (higher = better) |

## ğŸ”Œ API Quick Reference

### Health Check
```bash
GET /health
â†’ {"status": "ok", "version": "0.1.0"}
```

### Analyze Paper
```bash
POST /api/analyze
Content-Type: multipart/form-data
Body: file=<PDF/DOCX/TXT>

Response: {
  "plagiarism_score": 35.2,
  "ai_probability": 42.1,
  "citation_validity_score": 90.0,
  "statistical_risk_score": 15.0,
  "overall_research_credibility": 58.4,
  "plagiarism_matches": [...],
  "citation_invalid_dois": [...],
  "report_path": "reports/..."
}
```

### API Documentation
Interactive Swagger UI at `http://localhost:8000/docs`

## ğŸ§ª Testing

### Test Integration
```bash
cd backend
python scripts/test_api.py data/sample_paper.txt
```

### Test Frontend
Visit `http://localhost:5173` and upload a file

## ğŸ—ï¸ Project Structure

```
VeriPaper/
â”œâ”€â”€ backend/              # FastAPI application
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ main.py      # FastAPI setup
â”‚   â”‚   â”œâ”€â”€ api/routes.py # Analysis endpoint
â”‚   â”‚   â””â”€â”€ services/    # Plagiarism, AI, citation, stats modules
â”‚   â”œâ”€â”€ scripts/         # Training and testing scripts
â”‚   â”œâ”€â”€ data/            # Sample datasets
â”‚   â””â”€â”€ requirements.txt # Python dependencies
â”œâ”€â”€ frontend/            # React + Vite application
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ App.jsx      # Dashboard component
â”‚   â”‚   â”œâ”€â”€ ScoreGauge.jsx # Visualization
â”‚   â”‚   â””â”€â”€ api.js       # HTTP client
â”‚   â””â”€â”€ package.json     # npm dependencies
â”œâ”€â”€ QUICKSTART.md        # 5-minute setup guide
â”œâ”€â”€ DEVELOPMENT.md       # Detailed documentation
â””â”€â”€ README.md           # This file
```

## ğŸŒŸ Features Included

âœ… Multi-factor analysis (plagiarism, AI detection, citations, statistics)
âœ… SBERT embeddings + FAISS vector search
âœ… Logistic regression AI classifier
âœ… CrossRef API integration for citations
âœ… PDF report generation
âœ… React dashboard with real-time visualization
âœ… Multi-format export (PDF, CSV, JSON)
âœ… Analysis history with localStorage
âœ… Dark/light theme support
âœ… Responsive mobile design
âœ… Pre-trained AI detector model
âœ… Test scripts included
âœ… API documentation with Swagger UI

## ğŸ“š Technology Stack

### Backend
- FastAPI 0.115.0
- Python 3.11
- SBERT 3.0.1 (Sentence embeddings)
- FAISS 1.8.0 (Vector similarity)
- scikit-learn (Logistic regression)
- ReportLab (PDF generation)
- Requests (CrossRef API)

### Frontend
- React 18.3.1
- Vite 5.4.3
- Tailwind CSS 3.4.10
- Recharts 2.10.3
- Axios 1.7.7

## ğŸš¢ Deployment

### Docker
```bash
docker build -t veripaper-backend backend/
docker run -p 8000:8000 veripaper-backend

docker build -t veripaper-frontend frontend/
docker run -p 3000:3000 veripaper-frontend
```

### Cloud Platforms
- **Render**: Deploy backend with native Python support
- **Vercel**: Deploy frontend with automatic builds
- **AWS/GCP/Azure**: Use Docker containers

## ğŸ› ï¸ Configuration

Create `backend/.env`:
```
CROSSREF_DISABLE=0
REPORTS_DIR=backend/reports
```

## ğŸ“ License

MIT License - Free for academic and commercial use

## ğŸ¤ Contributing

Contributions welcome! Please see DEVELOPMENT.md for setup and architecture details.

## ğŸ“§ Support

- ğŸ“– Check QUICKSTART.md or DEVELOPMENT.md
- ğŸ› Review troubleshooting section
- ğŸ’¬ Open an issue on GitHub

---

**Ready to analyze?** Start with [QUICKSTART.md](QUICKSTART.md)  
**Want details?** Read [DEVELOPMENT.md](DEVELOPMENT.md)

**Version**: 0.1.0 (Beta) | **Status**: Under Active Development

### Setup
1. Install dependencies from frontend/package.json.
2. Run the dev server on port 5173.

### Notes
The frontend expects the backend at http://localhost:8000.

## Outputs
The analysis response includes scores, explanations, suspicious paragraph samples, and a report path for the generated PDF.

## AI Detector Training
Train the logistic regression model with a CSV that has columns text,label where label is 0 for human and 1 for AI.
Use backend/scripts/train_ai_detector.py and pass --data and --output. The default output path matches AI_MODEL_PATH.

## Launch Summary
Backend runs on http://localhost:8000 (API at /api/analyze) and frontend runs on http://localhost:5173.

## Testing
Run the test script to verify the end-to-end pipeline:
```bash
python backend/scripts/test_api.py backend/data/sample_paper.txt
```

## Architecture
- **Text Extraction**: PyMuPDF for PDFs, python-docx for DOCX, plain UTF-8 for TXT
- **Plagiarism Detection**: SBERT (all-MiniLM-L6-v2) embeddings + FAISS IndexFlatIP for semantic search
- **AI Detection**: Perplexity, lexical diversity, stopword frequency, repetition, punctuation entropy + optional trained logistic regression
- **Citation Validation**: Regex extraction + CrossRef API validation + year mismatch detection
- **Statistical Risk**: Repeated decimal patterns, unrealistic p-values
- **Scoring Formula**: 0.4 Ã— (100 - plagiarism) + 0.4 Ã— (100 - AI probability) + 0.2 Ã— citation_validity
